### 消息队列基础

#### 1.消息队列原理

未完待续

#### 2.如何保证消息的顺序性？

比如订单系统，一个完整的交易经历一系列的动作，订单状态也会随之变化，一个订单会产生多条MQ消息，下单、付款、发货、买家确认收获等，消费端需要严格按照业务状态额顺序处理，否则就会出现业务问题。

消息在投入到queue的时候是有顺序，如果只是单个消费者来处理对应的单个queue，是不会出现消息错乱的问题。但是在消费的时候有可能多个消费者消费同一个queue，由于各个消费者处理消息的时间不同，导致消息未能按照预期的顺序处理。**其实根本的问题就是如何保证消息按照预期的顺序处理完成。**

**出现消费顺序错乱的情况：**

- 为了提高处理效率，一个queue存在多个consumer

![avatar](img/queue/一个queue存在多个consumer.png)

- 一个queue只存在一个consumer，但是为了提高处理效率，consumer中使用了多线程进行处理

![avatar](img/queue/只有一个consumer，但使用了多线程进行处理.png)

**保证消息顺序性的方法：**

- 将原来的一个queue拆分成多个queue，每个queue都有一个自己的consumer。该种方案的核心是生产者在投递消息的时候**根据业务数据关键值（例如订单ID哈希值对订单队列数取模）来将需要保证先后顺序的同一类数据（同一个订单的数据）发送到同一个queue当中**。

![avatar](img/queue/消息顺序解决办法1，一个队列拆分为多个队列.png)

- 一个queue就一个consumer，在consumer中维护**多个内存队列，根据业务数据关键值（例如订单ID哈希值对内存队列数取模）将消息加入到不同的内存队列中**，然后多个真正负责处理消息的线程去各自对应的内存队列当中获取消息进行消费。

![avatar](img/queue/消息顺序解决办法2，只用一个消费者但是内部多线程取模处理.png)

**RabbitMQ保证消息顺序性总结：**

核心思路就是根据业务数据关键值划分成多个消息集合，而且每个消息集合中的消息数据都是有序的，每个消息集合有自己独立的一个consumer。多个消息集合的存在保证了消息消费的效率，每个有序的消息集合对应单个的consumer也保证了消息消费时的有序性。

### RabbitMQ

#### 1.RabbitMQ常见的交换器类型有哪几种？

RabbitMQ常见的交换器类型有`fanout`、`direct`、`topic`、`headers`四种。

**fanout**
它会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。

**direct**
它会把消息路由到那些`BindingKey`和`RoutingKey`完全匹配的队列中。

**topic**
在前面完全匹配的规则上进行了扩展，通过使用点号“.”分隔的字符串，使用基于通配符（`#`和`*`）的模式匹配的方式来绑定到路由键上。其中`#`用于匹配一个字符，`*`用于匹配一个或多个字符。如`image.*.key`可以匹配`image.cc.key`队列也可以支持`image.dd.key`队列。

**headers**
此类型不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的`headers`属性进行匹配。此类型性能较差，实用性不好。

#### 2.RabbitMQ如何保证被消费端确认？

消费者在订阅队列时，可以指定`autoAck`参数，当为`false`时，`RabbitMQ`会等待消费者显式地回复确认信号后才从内存（或者磁盘）中移去消息（实质是先打上删除标记，之后再删除）。当`autoAck`等于true时，`RabbitMQ`会自动把发送出去的消息置为确认，然后删除，而不管消费者是否真正的消费到了这些消息。

采用消息确认机制后，只要设置`autoAck`参数为`false`，消费者不用担心进程挂掉后消息丢失，因为`RabbitMQ`会一直等待并持有消息直到消费者显式调用`Basic.Ack`命令为止。

当`autoAck`参数置为`false`时，实际在`RabbitMQ`服务端队列消息分成了两部分：一部分是等待投递给消费者的消息；一部分是已经投递给消费者，但是还没有收到消费者确认信号的消息。如果`RabbitMQ`一直没有收到消费者的确认信号，并且消费此消息的消费者已经断开连接，则`RabbitMQ`会安排该消息重新进入队列，等待投递给下一个消费者，也有可能继续投递给原来的消费者。**这里要注意消息的幂等。**

#### 3.RabbitMQ如何实现延时消息？

可以通过设置队列`x-message-ttl`属性来强制规则消息的最大生存时间或者指定消息的`expiration`属性指定到期的时间（如果两个一起使用，则消息的TTL以两者之间较小的为准），同时指定死信交换器在消息过期的时候自动进入到死信队列中。

#### 4.设置队列的TTL属性和设置消息的TTL有什么区别？

如果设置队列TTL的属性，一旦消息过期，就会从队列中删除。而消息设置TTL一旦过期，不会马上从队列中删除，因为每条消息是否过期是在即将投递到消费者之前判断的。

为什么这两种方法处理的方式不一样？因为第一种方式里，队列中已过期的消息肯定在队列头部，`RabbitMQ`只要定期从队列头部开始扫描是否有过期的消息即可。而第二种方法里，每条消息的过期时间不同，如果要删除所有过期消息势必要扫描整个队列，所以不如等到此消息即将被消费时再判断是否过期，如果过期再进行删除操作即可。

#### 5.消息变成死信有几中情况？

当消息变成死信之后，它能被重新发送到另一个交换器，这个交换器叫做死信交换器（`Dead-Letter-Exchange`），绑定死信交换器的队列就称之为死信队列。

- 消息被拒绝，并且设置`requeue`参数为`false`；
- 消息过期；
- 队列达到最大长度；

未完待续

### kafka

#### 1.kafka的术语解释

> Kafka体系架构术语

- `Producer`：生产者，也就是发送消息的一方。生产者负责创建新消息，然后将其投递到kafka中。
- `Consumer`：消费者，也就是接收消息的一方。消费者连接到kafka上并接收消息，进行执行相应的业务逻辑处理。
- `Broker`：服务代理节点。对于kafka而言，broker可以简单的看作一个独立的kafka服务节点或kafka服务实例。大多数情况下也可以将broker看作一台kafka服务器，前提是服务器上只部署了一个kafka实例。一个或多个broker组成了一个kafka集群。

> 副本消费相关术语

- `AR`：分区中的所有副本统称为`AR`（`Assigned Replicas`）。`AR=ISR+OSR`，在正常情况下，所有的`follower`副本都应该与`leader`副本保持一定程度的同步，即`AR=ISR`，`OSR`集合为空。
- `ISR`：所有与`leader`副本保持一定程度同步的副本（包括`leader`副本在内）组成`ISR`（`In-Sync Replicas`）。`ISR`集合是`AR`集合中的一个子集，消息会先发送到`leader`副本，然后`follower`副本才能从`leader`副本中拉取消息进行同步，同步期间内`follower`副本相对于`leader`副本而言会有一定程度的滞后。
- `OSR`：与`leader`副本同步滞后过多的副本（不包括`leader`副本）组成`OSR`（`Out-of-Sync Replicas`）。
- `HW`：俗称高水位（`High Watermark`），它标识了一个特定的消息偏移量，消费者只能拉取到这个offset之前的消息。
- `LEO`：它标识当前日志文件中下一条待写入消息的offset（`Log End Offset`）。分区`ISR`集合中的每个副本都会维护自身的`LEO`，而`ISR`集合中`最小的LEO`即为分区的`HW`，对消费者而言`只能消费HW之前的消息`。

#### 1.kafka的存储结构

Kafka中的`Message`是以`topic`为基本单位组织的，不同的`topic`之间是相互独立的。每个`topic`又可以分成几个不同的`partition`(每个`topic`有几个`partition`是在创建`topic`时指定的)，每个`partition`存储一部分`Message`。

`partition`是以文件的形式存储在文件系统中，比如，创建了一个名为`page_visits`的`topic`，其有5个`partition`，那么在Kafka的数据目录中(由配置文件中的`log.dirs`指定的)中就有这样5个目录: `page_visits-0`，`page_visits-1`，`page_visits-2`，`page_visits-3`，`page_visits-4`，其命名规则为`<topic_name>-<partition_id>`，里面存储的分别就是这5个`partition`的数据。

`partition`中的每条`Message`由`offset`来表示它在这个`partition`中的偏移量，这个`offset`不是该`Message`在`partition`数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了`partition`中的一条`Message`。

![avatar](img/kafka数据存储结构.png)

某些时候可能会如下布局

![avatar](img/kafka数据存储结构2.png)

#### 2.消息传输的保障有哪几层？

一般而言，消息中间件的消息传输保障有3个层级，分别如下：
- `at most once`：至多一次。消息可能会丢失，但绝对不会重复传输。
- `at least once`：最少一次。消息绝对不会丢失，但可能会重复传输。
- `exactly once`：恰好一次。每条消息肯定会被传输一次且仅传输一次。

#### 3.kafka生产者和消费者的消息传输保障分别是什么？

> 生产者

当生产者向kafka发送消息时，一旦消息被成功提交到日志文件，由于多副本机制的存在，这条消息就不会丢失。如果生产者发送消息到kafka之后，遇到了网络等原因中断了，那么生产者就无法判断该消息是否已经提交。生产者可以进行多次重试来确保消息已经写入kafka，这个重试的过程中有可能会造成消息的重复写入，所以这里kafka提供的消息传输保障为`at least once`。

> 消费者

消费者处理消息和提交消息位移的顺序在很大程度上决定了消费者提供哪一种消息传输保障。

如果消费者在拉取完消息之后，应用逻辑先处理消息后提交消息位移，那么在消息处理之后且在位移提交之前消费者宕机了，待它重新上线之后，会从上一次位移提交的位置拉取，这样就出现了重复消费，因为有部分消息已经处理过了只是还没来得及提交消费位移，此时就对应`at least once`。

如果消费者在拉取完消息之后，应用逻辑先提交消费位移后进行消息处理，那么在位移提交之后且在消息处理完成之前消费者宕机了，待它重新上线之后，会从已经提交的位移处开始拉取消息，如此会造成部分消息丢失，此时就对应`at most once`。

#### 4.kafka是如何保证Exactly Once？

kafka从0.11.0.0版本开始引入了幂等（`idempotent`）和`acks = -1`时的`at least once`这两个特性，以此来实现`EOS`(`exactly once`)。

使用时，只需将`enable.idempotence`属性设置为true，kafka自动将`acks`属性设为-1。

#### 5.kafka的isr及其实现方式

在kafka的follower副本与leader副本保持在一定成都的滞后内，则组成ISR（In-Sync Replicas）。如果一个`Follower`宕机，或者落后太多，`Leader`将把它从`ISR`中移除。

对一个节点是否存活有这样两个条件判断：
- 第一个，节点必须维护和zookeeper的连接，zookeeper通过心跳机制检查每个节点的连接；
- 第二个，如果节点时follower，它必要能及时同步与leader的写操作，不是延时太久。

如果满足上面2个条件，就可以说节点时“in-sync“（同步中的）。leader会追踪”同步中的“节点，如果有节点挂了，卡了，或延时太久，那么leader会它移除，延时的时间由参数`replica.log.max.messages`决定，判断是不是卡住了，由参数`replica.log.time.max.ms`决定。

#### 6.HW和LEO是什么，起到什么作用？

`HW`是`High Watermark`的缩写，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。

`LEO`是`Log End Offset`的缩写，它标识当前日志文件中下一条待写入消息的offset，`LEO`的大小相当于日志分区中最后一条消息的offset值加1。分区`ISR`集合中的每个副本都会维护自身的`LEO`，而`ISR集合中最小的LEO即为分区的HW`，对消费者而言只能消费`HW之前`的消息。

**其作用是有效地权衡了数据可靠性和性能之间的关系**

kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认为已成功提交，这种复制方式极大的影响了性能。而在异步复制方式下，follower副本异步地从leader副本中复制数据，数据只要被leader副本写入就认为已经成功提交了。在这种情况下，如果follower副本都还没有复制完而落后于leader副本，突然leader副本宕机，则会造成数据丢失。

![avatar](img/kafka的leo和hw.png)

#### 7.kafka的rebalance的原因和解决

`Rebalance`本质上是一种协议，规定了一个`Consumer Group`下的所有`consumer`如何达成一致，来分配订阅`Topic`的每个分区。

> 触发`Rebalance`的时机:

- 组成员个数发生变化。例如有新的`consumer`实例加入该消费组或者离开组。
- `Consumer Group`所对应的节点发生了变更。
- 订阅`Topic`的个数发生变化。
- 订阅`Topic`的分区数发生变化。

`Rebalance`发生时，`Group`下所有`consumer`实例都会协调在一起共同参与，`kafka`能够保证尽量达到最公平的分配。但是`Rebalance`过程对`consumer group`会造成比较严重的影响。在`Rebalance`的过程中`consumer group`下的所有消费者实例都会停止工作，等待`Rebalance`过程完成。

> 解决办法

其中订阅`Topic`个数和分区数变化可以认为避免。常见的还是主成员个数的变化。

消费者成员正常的添加和停掉导致`rebalance`，这种情况无法避免，但是时在某些情况下，`Consumer`实例会被`Coordinator`错误地认为 “已停止” 从而被“踢出”Group。从而导致`rebalance`。

当`Consumer Group`完成`Rebalance`之后，每个`Consumer`实例都会定期地向`Coordinator`发送心跳请求，表明它还存活着。如果某个`Consumer`实例不能及时地发送这些心跳请求，`Coordinator`就会认为该`Consumer`已经 “死” 了，从而将其从`Group`中移除，然后开启新一轮`Rebalance`。这个时间可以通过`Consumer`端的参数`session.timeout.ms`进行配置。默认值是`10`秒。

除了这个参数，`Consumer`还提供了一个控制发送心跳请求频率的参数，就是`heartbeat.interval.ms`。这个值设置得越小，`Consumer`实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启`Rebalance`，因为，目前`Coordinator`通知各个`Consumer`实例开启`Rebalance`的方法，就是将`REBALANCE_NEEDED`标志封装进心跳请求的响应体中。

除了以上两个参数，`Consumer`端还有一个参数，用于控制`Consumer`实际消费能力对`Rebalance`的影响，即`max.poll.interval.ms`参数。它限定了`Consumer`端应用程序两次调用`poll`方法的最大时间间隔。它的默认值是`5`分钟，表示你的`Consumer`程序如果在`5`分钟之内无法消费完`poll`方法返回的消息，那么`Consumer`会主动发起 “离开组” 的请求，`Coordinator`也会开启新一轮`Rebalance`。

通过上面的分析，我们可以看一下那些`rebalance`是可以避免的：

第一类非必要`Rebalance`是因为未能及时发送心跳，导致`Consumer`被 “踢出”Group 而引发的。这种情况下我们可以设置`session.timeout.ms`和`heartbeat.interval.ms`的值，来尽量避免`rebalance`的出现。（以下的配置是在网上找到的最佳实践，暂时还没测试过）

- 设置`session.timeout.ms = 6s`。
- 设置`heartbeat.interval.ms = 2s`。
- 要保证`Consumer`实例在被判定为“dead” 之前，能够发送至少`3轮`的心跳请求，即`session.timeout.ms >= 3 * heartbeat.interval.ms`。
- 将`session.timeout.ms`设置成 6s 主要是为了让`Coordinator`能够更快地定位已经挂掉的`Consumer`，早日把它们踢出Group。

第二类非必要`Rebalance`是`Consumer`消费时间过长导致的。此时，`max.poll.interval.ms`参数值的设置显得尤为关键。如果要避免非预期的`Rebalance`，你最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。总之，要为业务处理逻辑留下充足的时间。这样，`Consumer`就不会因为处理这些消息的时间太长而引发`Rebalance`。

未完待续